# Neural Networks

## Motivation

## Categories

### Perceptron

感知器诞生于1957年，简单来说，就是一种二元线性分类器。二元体现在不管输入是什么，输出的分类结果只有1和0，线性体现在。它的灵感来源于人类的神经细胞。
单个神经细胞可被视为一种只有两种状态的机器，激活时为'1'，未激活时为'0'。神经细胞的状态取决于从其他的神经细胞收到的输入信号量，及突触的强度，当
信号量的总和超过了某个阈值时，细胞体就会被激活，产生电脉冲。

感知器的主要缺陷是不能处理线性不可分问题。

[感知器图示](img/perceptron.png)

### Feed-forward Network

累积BP算法直接针对累积误差最小化，它再读取整个训练集D一遍后才对参数进行更新，其参数更新的频率低得多。但在很多任务中，累积误差下降到一定程度之后，进一步下降会非常缓慢，这时标准BP往往会更快获得较好的解，尤其在训练集D非常大时。

[Hornik et.al 1989]证明，只需一个包含足够多神经元的隐层，多层前馈网络就能以任意精度逼近任意复杂度的连续函数。

由于其强大的表示能力，BP神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。有两种策略常用来缓解BP网络的过拟合，第一个策略是early stopping，将数据分成训练集和测试集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。第二种策略是regularization，其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和。

基于梯度的搜索是使用最为广泛的参数寻优方法。
